{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c01c55b",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7764d6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c4e328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\91637\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91637\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from empath import Empath\n",
    "import re\n",
    "import fasttext\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10c54a",
   "metadata": {},
   "source": [
    "# Handling datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a50ed240",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\Dataset.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['neg'] = -1\n",
    "df['neu'] = 0\n",
    "df['pos'] = 1\n",
    "df['compound'] = 0\n",
    "\n",
    "def cleaning(text):\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)            #removing everything except the characters\n",
    "    words = text.split()\n",
    "\n",
    "    #Lemmatizing the words\n",
    "    words = [lemmatizer.lemmatize(word) for word in  words if not word in stopwords.words('english')]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcdd79a",
   "metadata": {},
   "source": [
    "# Build functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "759b6f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>TextBlob_Subjectivity</th>\n",
       "      <th>TextBlob_Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tuesdayvibes</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Love vacation vibe amazing beautiful cabo mexi...</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.214572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>realmeC11</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Best Camera Smartphone k Please vote help reac...</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501977</td>\n",
       "      <td>0.134387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>KPSharmaOli</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>shree Why problem people We problem Stupid Com...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738750</td>\n",
       "      <td>0.018750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RheaChakraborty</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>Rhea Chakraborty Heartbreaking Post On Sushant...</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Stop_Transfer_Sunita_Yadav</td>\n",
       "      <td>7/14/2020</td>\n",
       "      <td>7:00:21</td>\n",
       "      <td>We stand Sunita Yadav Stop Transfer Where woma...</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515079</td>\n",
       "      <td>0.213228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         Data       Date     Time  \\\n",
       "0           0                 tuesdayvibes  7/14/2020  7:00:21   \n",
       "1           1                    realmeC11  7/14/2020  7:00:21   \n",
       "2           2                  KPSharmaOli  7/14/2020  7:00:21   \n",
       "3           3              RheaChakraborty  7/14/2020  7:00:21   \n",
       "4           4   Stop_Transfer_Sunita_Yadav  7/14/2020  7:00:21   \n",
       "\n",
       "                                        tweetcaption    neg    neu    pos  \\\n",
       "0  Love vacation vibe amazing beautiful cabo mexi...  0.055  0.748  0.197   \n",
       "1  Best Camera Smartphone k Please vote help reac...  0.033  0.829  0.139   \n",
       "2  shree Why problem people We problem Stupid Com...  0.100  0.771  0.129   \n",
       "3  Rhea Chakraborty Heartbreaking Post On Sushant...  0.133  0.668  0.199   \n",
       "4  We stand Sunita Yadav Stop Transfer Where woma...  0.206  0.600  0.194   \n",
       "\n",
       "   compound  TextBlob_Subjectivity  TextBlob_Polarity  \n",
       "0         0               0.550000           0.214572  \n",
       "1         0               0.501977           0.134387  \n",
       "2         0               0.738750           0.018750  \n",
       "3         0               0.607143           0.142857  \n",
       "4         0               0.515079           0.213228  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "lexicon = Empath()\n",
    "\n",
    "df['tweetcaption'] = [cleaning(text) for text in df['tweetcaption']]\n",
    "df['TextBlob_Subjectivity'] = [getSubjectivity(text) for text in df['tweetcaption']]\n",
    "df['TextBlob_Polarity'] = [getPolarity(text) for text in df['tweetcaption']]\n",
    "for i in range(df.shape[0]):\n",
    "    scores = sid.polarity_scores(df.iat[i, 4])\n",
    "    df.iat[i, 5] = scores['neg']\n",
    "    df.iat[i, 6] = scores['neu']\n",
    "    df.iat[i, 7] = scores['pos']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ede23d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Data</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>tweetcaption</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>TextBlob_Subjectivity</th>\n",
       "      <th>TextBlob_Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35261</th>\n",
       "      <td>35261</td>\n",
       "      <td>SwaraBhasker</td>\n",
       "      <td>9/14/2020</td>\n",
       "      <td>13:00:01</td>\n",
       "      <td>I never seen SwaraBhasker supporting right thi...</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528902</td>\n",
       "      <td>0.092130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35262</th>\n",
       "      <td>35262</td>\n",
       "      <td>TukdeTukdeGang</td>\n",
       "      <td>9/14/2020</td>\n",
       "      <td>13:00:01</td>\n",
       "      <td>hindu DelhiRiots Best thing happened TukdeTukd...</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504888</td>\n",
       "      <td>0.011470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35263</th>\n",
       "      <td>35263</td>\n",
       "      <td>IndooKiJawani</td>\n",
       "      <td>9/14/2020</td>\n",
       "      <td>13:00:01</td>\n",
       "      <td>The team IndooKiJawani surprise audience amp a...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.264286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35264</th>\n",
       "      <td>35264</td>\n",
       "      <td>DelhiRiots2020</td>\n",
       "      <td>9/14/2020</td>\n",
       "      <td>13:00:01</td>\n",
       "      <td>The people India protest demand investigation ...</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392432</td>\n",
       "      <td>0.281122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35265</th>\n",
       "      <td>35265</td>\n",
       "      <td>SevaSaptah</td>\n",
       "      <td>9/14/2020</td>\n",
       "      <td>13:00:01</td>\n",
       "      <td>On auspicious occasion SevaSaptah We coperate ...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.113333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             Data       Date      Time  \\\n",
       "35261       35261     SwaraBhasker  9/14/2020  13:00:01   \n",
       "35262       35262   TukdeTukdeGang  9/14/2020  13:00:01   \n",
       "35263       35263    IndooKiJawani  9/14/2020  13:00:01   \n",
       "35264       35264   DelhiRiots2020  9/14/2020  13:00:01   \n",
       "35265       35265       SevaSaptah  9/14/2020  13:00:01   \n",
       "\n",
       "                                            tweetcaption    neg    neu    pos  \\\n",
       "35261  I never seen SwaraBhasker supporting right thi...  0.158  0.633  0.208   \n",
       "35262  hindu DelhiRiots Best thing happened TukdeTukd...  0.118  0.666  0.216   \n",
       "35263  The team IndooKiJawani surprise audience amp a...  0.054  0.797  0.149   \n",
       "35264  The people India protest demand investigation ...  0.106  0.781  0.114   \n",
       "35265  On auspicious occasion SevaSaptah We coperate ...  0.010  0.818  0.172   \n",
       "\n",
       "       compound  TextBlob_Subjectivity  TextBlob_Polarity  \n",
       "35261         0               0.528902           0.092130  \n",
       "35262         0               0.504888           0.011470  \n",
       "35263         0               0.471429           0.264286  \n",
       "35264         0               0.392432           0.281122  \n",
       "35265         0               0.333333           0.113333  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2b55ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7043907446265524"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"neu\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.polarity_scores(\"India is Great!\")\n",
    "def violent_or_not(text):\n",
    "    score = lexicon.analyze(text, categories=[\"violence\"])\n",
    "    return score['violence']\n",
    "lexicon.analyze(\"he bled to death\", categories=['violence'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54efe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
